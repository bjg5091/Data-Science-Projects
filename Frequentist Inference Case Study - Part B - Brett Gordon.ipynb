{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequentist Inference Case Study - Part B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to Part B of the Frequentist inference case study! The purpose of this case study is to help you apply the concepts associated with Frequentist inference in Python. In particular, you'll practice writing Python code to apply the following statistical concepts: \n",
    "* the _z_-statistic\n",
    "* the _t_-statistic\n",
    "* the difference and relationship between the two\n",
    "* the Central Limit Theorem, including its assumptions and consequences\n",
    "* how to estimate the population mean and standard deviation from a sample\n",
    "* the concept of a sampling distribution of a test statistic, particularly for the mean\n",
    "* how to combine these concepts to calculate a confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebook, we used only data from a known normal distribution. **You'll now tackle real data, rather than simulated data, and answer some relevant real-world business problems using the data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hospital medical charges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that a hospital has hired you as their data scientist. An administrator is working on the hospital's business operations plan and needs you to help them answer some business questions. \n",
    "\n",
    "In this assignment notebook, you're going to use frequentist statistical inference on a data sample to answer the questions:\n",
    "* has the hospital's revenue stream fallen below a key threshold?\n",
    "* are patients with insurance really charged different amounts than those without?\n",
    "\n",
    "Answering that last question with a frequentist approach makes some assumptions, and requires some knowledge, about the two groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use some data on medical charges obtained from [Kaggle](https://www.kaggle.com/easonlai/sample-insurance-claim-prediction-dataset). \n",
    "\n",
    "For the purposes of this exercise, assume the observations are the result of random sampling from our single hospital. Recall that in the previous assignment, we introduced the Central Limit Theorem (CLT), and its consequence that the distributions of sample statistics approach a normal distribution as $n$ increases. The amazing thing about this is that it applies to the sampling distributions of statistics that have been calculated from even highly non-normal distributions of data! Recall, also, that hypothesis testing is very much based on making inferences about such sample statistics. You're going to rely heavily on the CLT to apply frequentist (parametric) tests to answer the questions in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import t\n",
    "from numpy.random import seed\n",
    "medical = pd.read_csv('insurance2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1338, 8)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "      <th>insuranceclaim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>16884.92400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1725.55230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4449.46200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21984.47061</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3866.85520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex     bmi  children  smoker  region      charges  insuranceclaim\n",
       "0   19    0  27.900         0       1       3  16884.92400               1\n",
       "1   18    1  33.770         1       0       2   1725.55230               1\n",
       "2   28    1  33.000         3       0       2   4449.46200               0\n",
       "3   33    1  22.705         0       0       1  21984.47061               0\n",
       "4   32    1  28.880         0       0       1   3866.85520               1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medical.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q1:__ Plot the histogram of charges and calculate the mean and standard deviation. Comment on the appropriateness of these statistics for the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method ppf in module scipy.stats._distn_infrastructure:\n",
      "\n",
      "ppf(q, *args, **kwds) method of scipy.stats._continuous_distns.t_gen instance\n",
      "    Percent point function (inverse of `cdf`) at q of the given RV.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    q : array_like\n",
      "        lower tail probability\n",
      "    arg1, arg2, arg3,... : array_like\n",
      "        The shape parameter(s) for the distribution (see docstring of the\n",
      "        instance object for more information)\n",
      "    loc : array_like, optional\n",
      "        location parameter (default=0)\n",
      "    scale : array_like, optional\n",
      "        scale parameter (default=1)\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    x : array_like\n",
      "        quantile corresponding to the lower tail probability q.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(t.ppf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(medical['charges'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 13270.422265141257\n",
      "Standard Deviation: 12105.484975561605\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(medical['charges'])\n",
    "std = np.std(medical['charges'])\n",
    "print(\"Mean: \" + str(mean))\n",
    "print(\"Standard Deviation: \" + str(std))\n",
    "\n",
    "#These statistics are not very indicitive of the data as the data is skewed heavily. With the standard deviation nearly\n",
    "#being equal to the mean in a category where the value cannot be below 0, these cannot be used as a baseline to find a\n",
    "#two-sided 95% confidence interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q2:__ The administrator is concerned that the actual average charge has fallen below 12,000, threatening the hospital's operational model. On the assumption that these data represent a random sample of charges, how would you justify that these data allow you to answer that question? And what would be the most appropriate frequentist test, of the ones discussed so far, to apply?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ There is a large enough sample size to justify the data. The frequentist test needs to be a confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q3:__ Given the nature of the administrator's concern, what is the appropriate confidence interval in this case? A ***one-sided*** or ***two-sided*** interval? (Refresh your understanding of this concept on p. 399 of the *AoS*). Calculate the critical value and the relevant 95% confidence interval for the mean, and comment on whether the administrator should be concerned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ An appropriate confidence interval would be one-sided because of how skewed it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean minus critical value and alpha = 0.95 NOT 0.975\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6459941145571317 1338\n"
     ]
    }
   ],
   "source": [
    "n = medical['charges'].count()\n",
    "t_critical = t.ppf(0.95, n-1)\n",
    "print(t_critical, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Margin of error is 544.7314053390934\n",
      "Confidence interval of 95% is: 12725.690859802164\n"
     ]
    }
   ],
   "source": [
    "margin_of_error = t_critical * (std/np.sqrt(n))\n",
    "print(\"Margin of error is \" + str(margin_of_error))\n",
    "\n",
    "confidence_interval = (mean - margin_of_error)\n",
    "print(\"Confidence interval of 95% is: \" + str(confidence_interval))\n",
    "\n",
    "#Confidence interval of 12725.7 is below that of the sample mean so the administrator should not be concerned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The administrator then wants to know whether people with insurance really are charged a different amount to those without.\n",
    "\n",
    "__Q4:__ State the null and alternative hypothesis here. Use the _t_-test for the difference between means, where the pooled standard deviation of the two groups is given by:\n",
    "\\begin{equation}\n",
    "s_p = \\sqrt{\\frac{(n_0 - 1)s^2_0 + (n_1 - 1)s^2_1}{n_0 + n_1 - 2}}\n",
    "\\end{equation}\n",
    "\n",
    "and the *t*-test statistic is then given by:\n",
    "\n",
    "\\begin{equation}\n",
    "t = \\frac{\\bar{x}_0 - \\bar{x}_1}{s_p \\sqrt{1/n_0 + 1/n_1}}.\n",
    "\\end{equation}\n",
    "\n",
    "(If you need some reminding of the general definition of ***t-statistic***, check out the definition on p. 404 of *AoS*). \n",
    "\n",
    "What assumption about the variances of the two groups are we making here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ The null hypothesis is that people with insurance are not charged a different amount from those without. The alternate hypothesis is that the two groups are charged a different amount. There is an assumption that the variance of the two groups is equal.\n",
    "\n",
    "#list of charges that are insured and list of charges not insured. n0 would be list of charges uninsured. n1 would be list of charges insured. x-bar0 would be mean of charges that are uninsured. s = standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q5:__ Perform this hypothesis test both manually, using the above formulae, and then using the appropriate function from [scipy.stats](https://docs.scipy.org/doc/scipy/reference/stats.html#statistical-tests) (hint, you're looking for a function to perform a _t_-test on two independent samples). For the manual approach, calculate the value of the test statistic and then its probability (the p-value). Verify you get the same results from both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783 555 16423.928276537663 8821.421892306294 14036.956250260411 6440.699841605233\n"
     ]
    }
   ],
   "source": [
    "ins_claim = medical[medical['insuranceclaim'] == 1]\n",
    "no_ins_claim = medical[medical['insuranceclaim'] == 0]\n",
    "\n",
    "n1 = ins_claim['charges'].count()\n",
    "n0 = no_ins_claim['charges'].count()\n",
    "\n",
    "ins_mean = np.mean(ins_claim['charges'])\n",
    "no_ins_mean = np.mean(no_ins_claim['charges'])\n",
    "\n",
    "s1 = np.std(ins_claim['charges'])\n",
    "s0 = np.std(no_ins_claim['charges'])\n",
    "print(n1, n0, ins_mean, no_ins_mean, s1, s0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11512.282899205744"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top = (n0-1)*s0**2+(n1-1)*s1**2\n",
    "bottom = n0 + n1 - 2\n",
    "\n",
    "pooled_std = np.sqrt(top/bottom)\n",
    "#pooled_std = np.sqrt(((n0-1)*s0**2+(n1-1)*s1**2))\n",
    "pooled_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.901306943555385"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_bottom = pooled_std*np.sqrt((1/n0)+(1/n1))\n",
    "\n",
    "t_value = (ins_mean - no_ins_mean)/t_bottom\n",
    "\n",
    "t_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ttest_ind_from_stats in module scipy.stats.stats:\n",
      "\n",
      "ttest_ind_from_stats(mean1, std1, nobs1, mean2, std2, nobs2, equal_var=True, alternative='two-sided')\n",
      "    T-test for means of two independent samples from descriptive statistics.\n",
      "    \n",
      "    This is a two-sided test for the null hypothesis that two independent\n",
      "    samples have identical average (expected) values.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    mean1 : array_like\n",
      "        The mean(s) of sample 1.\n",
      "    std1 : array_like\n",
      "        The standard deviation(s) of sample 1.\n",
      "    nobs1 : array_like\n",
      "        The number(s) of observations of sample 1.\n",
      "    mean2 : array_like\n",
      "        The mean(s) of sample 2.\n",
      "    std2 : array_like\n",
      "        The standard deviations(s) of sample 2.\n",
      "    nobs2 : array_like\n",
      "        The number(s) of observations of sample 2.\n",
      "    equal_var : bool, optional\n",
      "        If True (default), perform a standard independent 2 sample test\n",
      "        that assumes equal population variances [1]_.\n",
      "        If False, perform Welch's t-test, which does not assume equal\n",
      "        population variance [2]_.\n",
      "    alternative : {'two-sided', 'less', 'greater'}, optional\n",
      "        Defines the alternative hypothesis.\n",
      "        The following options are available (default is 'two-sided'):\n",
      "    \n",
      "          * 'two-sided'\n",
      "          * 'less': one-sided\n",
      "          * 'greater': one-sided\n",
      "    \n",
      "        .. versionadded:: 1.6.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    statistic : float or array\n",
      "        The calculated t-statistics.\n",
      "    pvalue : float or array\n",
      "        The two-tailed p-value.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    scipy.stats.ttest_ind\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    .. versionadded:: 0.16.0\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] https://en.wikipedia.org/wiki/T-test#Independent_two-sample_t-test\n",
      "    \n",
      "    .. [2] https://en.wikipedia.org/wiki/Welch%27s_t-test\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    Suppose we have the summary data for two samples, as follows::\n",
      "    \n",
      "                         Sample   Sample\n",
      "                   Size   Mean   Variance\n",
      "        Sample 1    13    15.0     87.5\n",
      "        Sample 2    11    12.0     39.0\n",
      "    \n",
      "    Apply the t-test to this data (with the assumption that the population\n",
      "    variances are equal):\n",
      "    \n",
      "    >>> from scipy.stats import ttest_ind_from_stats\n",
      "    >>> ttest_ind_from_stats(mean1=15.0, std1=np.sqrt(87.5), nobs1=13,\n",
      "    ...                      mean2=12.0, std2=np.sqrt(39.0), nobs2=11)\n",
      "    Ttest_indResult(statistic=0.9051358093310269, pvalue=0.3751996797581487)\n",
      "    \n",
      "    For comparison, here is the data from which those summary statistics\n",
      "    were taken.  With this data, we can compute the same result using\n",
      "    `scipy.stats.ttest_ind`:\n",
      "    \n",
      "    >>> a = np.array([1, 3, 4, 6, 11, 13, 15, 19, 22, 24, 25, 26, 26])\n",
      "    >>> b = np.array([2, 4, 6, 9, 11, 13, 14, 15, 18, 19, 21])\n",
      "    >>> from scipy.stats import ttest_ind\n",
      "    >>> ttest_ind(a, b)\n",
      "    Ttest_indResult(statistic=0.905135809331027, pvalue=0.3751996797581486)\n",
      "    \n",
      "    Suppose we instead have binary data and would like to apply a t-test to\n",
      "    compare the proportion of 1s in two independent groups::\n",
      "    \n",
      "                          Number of    Sample     Sample\n",
      "                    Size    ones        Mean     Variance\n",
      "        Sample 1    150      30         0.2        0.16\n",
      "        Sample 2    200      45         0.225      0.174375\n",
      "    \n",
      "    The sample mean :math:`\\hat{p}` is the proportion of ones in the sample\n",
      "    and the variance for a binary observation is estimated by\n",
      "    :math:`\\hat{p}(1-\\hat{p})`.\n",
      "    \n",
      "    >>> ttest_ind_from_stats(mean1=0.2, std1=np.sqrt(0.16), nobs1=150,\n",
      "    ...                      mean2=0.225, std2=np.sqrt(0.17437), nobs2=200)\n",
      "    Ttest_indResult(statistic=-0.564327545549774, pvalue=0.5728947691244874)\n",
      "    \n",
      "    For comparison, we could compute the t statistic and p-value using\n",
      "    arrays of 0s and 1s and `scipy.stat.ttest_ind`, as above.\n",
      "    \n",
      "    >>> group1 = np.array([1]*30 + [0]*(150-30))\n",
      "    >>> group2 = np.array([1]*45 + [0]*(200-45))\n",
      "    >>> ttest_ind(group1, group2)\n",
      "    Ttest_indResult(statistic=-0.5627179589855622, pvalue=0.573989277115258)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind_from_stats\n",
    "help(ttest_ind_from_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-11.901306943555387, pvalue=4.090550214373679e-31)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_auto = ttest_ind_from_stats(no_ins_mean, s0, n0, ins_mean, s1, n1)\n",
    "\n",
    "t_auto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Hopefully you got the exact same numerical results. This shows that you correctly calculated the numbers by hand. Secondly, you used the correct function and saw that it's much easier to use. All you need to do is pass your data to it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Q6:__ Conceptual question: look through the documentation for statistical test functions in scipy.stats. You'll see the above _t_-test for a sample, but can you see an equivalent one for performing a *z*-test from a sample? Comment on your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__A:__ There is no equivalent one because z-test is used for population data when parameters are known, not sample sizes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having completed this project notebook, you now have good hands-on experience:\n",
    "* using the central limit theorem to help you apply frequentist techniques to answer questions that pertain to very non-normally distributed data from the real world\n",
    "* performing inference using such data to answer business questions\n",
    "* forming a hypothesis and framing the null and alternative hypotheses\n",
    "* testing this using a _t_-test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
